{{- $app := .Values.vllm -}}
{{- if eq $app.workload.type "deployment" }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "vllm-basic.fullname" . }}
spec:
  replicas: {{ $app.workload.deployment.replicaCount }}
  strategy: {{ toYaml $app.workload.deployment.rollouts.strategy | nindent 4 }}
  selector:
    matchLabels:
      app: {{ include "vllm-basic.name" . }}
  template:
    metadata:
      labels:
        app: {{ include "vllm-basic.name" . }}
    spec:
      tolerations: {{ toYaml $app.tolerations | nindent 8 }}
      affinity: {{ toYaml $app.affinity | nindent 8 }}
      containers:
        - name: {{ include "vllm-basic.name" . }}
          image: "{{ $app.image.repository }}:{{ $app.image.tag }}"
          imagePullPolicy: {{ $app.image.pullPolicy }}
          args:
            - "--model"
            - "{{ $app.model }}"
            {{- range $arg := $app.extraArgs }}
            - "{{ $arg }}"
            {{- end }}
          ports:
            - name: {{ $app.port.name }}
              containerPort: {{ $app.port.containerPort }}
              protocol: {{ $app.port.protocol }}
          readinessProbe: {{ include "vllm-basic.renderProbe" (dict "probe" $app.readinessProbe "port" $app.port.containerPort) | nindent 12 }}
          livenessProbe: {{ include "vllm-basic.renderProbe" (dict "probe" $app.livenessProbe "port" $app.port.containerPort) | nindent 12 }}
          resources: {{ toYaml $app.resources | nindent 12 }}
          env: {{ include "vllm-basic.envVars" . | nindent 12 }}
          volumeMounts: {{ include "vllm-basic.volumeMounts" . | nindent 12 }}
      volumes: {{ include "vllm-basic.volumes" . | nindent 10 }}
---
{{- if $app.workload.deployment.autoScale.enabled }}
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: {{ include "vllm-basic.fullname" . }}
spec:
  scaleTargetRef:
    kind: Deployment
    name: {{ include "vllm-basic.fullname" . }}
  pollingInterval:  {{ $app.workload.deployment.autoScale.pollingInterval }}
  cooldownPeriod:   {{ $app.workload.deployment.autoScale.cooldownPeriod }}
  minReplicaCount:  {{ $app.workload.deployment.autoScale.minReplicas }}
  maxReplicaCount:  {{ $app.workload.deployment.autoScale.maxReplicas }}
  triggers:
  - type: prometheus
    metadata:
      serverAddress: {{ .Values.prometheus.serverURL }}
      metricName: "vllm:gpu_cache_usage_perc"
      threshold: "{{ $app.workload.deployment.autoScale.cacheUtilizationThreshold }}"
      query: '100*avg(vllm:gpu_cache_usage_perc{model_name="{{ $app.model }}"})'
{{- end }}
{{- end }}
